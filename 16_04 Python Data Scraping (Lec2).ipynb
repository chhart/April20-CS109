{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scraping (CS 109 - Lec2)\n",
    "\n",
    "Based on: https://github.com/cs109/2015/tree/master/Lectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all imports\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "from urllib import request # urllib2 isn't supported by P3 - https://stackoverflow.com/questions/58794540/no-module-named-urllib2-how-do-i-use-it-in-python-so-i-can-make-a-request\n",
    "import bs4 #this is beautiful soup\n",
    "import time\n",
    "import operator\n",
    "import socket\n",
    "import pickle # was CPickle, but again use pickly for P3\n",
    "import re # regular expressions\n",
    "import csv\n",
    "from datetime import date as d\n",
    "\n",
    "from pandas import Series\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from secrets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to effectively scrape, we need to understand a little HTML:\n",
    "\n",
    "This is an example for a minimal webpage defined in HTML tags. The root tag is html and then you have the head tag. This part of the page typically includes the title of the page and might also have other meta information like the author or keywords that are important for search engines. The body tag marks the actual content of the page. You can play around with the h2 tag trying different header levels. They range from 1 to 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "  <head>\n",
       "    <title>This is a title</title>\n",
       "  </head>\n",
       "  <body>\n",
       "    <h2> Test </h2>\n",
       "    <p>Hello world!</p>\n",
       "  </body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htmlString = \"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "    <title>This is a title</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h2> Test </h2>\n",
    "    <p>Hello world!</p>\n",
    "  </body>\n",
    "</html>\"\"\"\n",
    "\n",
    "htmlOutput = HTML(htmlString)\n",
    "htmlOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping a simple webpage\n",
    "\n",
    "a beautifully simple webpage (the Beautiful Soup info page): http://www.crummy.com/software/BeautifulSoup\n",
    "\n",
    "In Chrome: Ctrl+Shift+I shows the html - allowing me to to search for what I want\n",
    "\n",
    "### Scraping with Python\n",
    "different useful libraries:\n",
    "* urllib\n",
    "* beautifulsoup\n",
    "* pattern\n",
    "* soupy\n",
    "* LXML\n",
    "...\n",
    "\n",
    "The following cell just defines a url as a string and then reads the data from that url using the urllib library. If you uncomment the print command you see that we got the whole HTML content of the page into the string variable source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.crummy.com/software/BeautifulSoup'\n",
    "source = request.urlopen(url).read().decode() # decode needed due to bug(?) that returns the output from urlopen as bytes instead of string\n",
    "# print(source) # uncomment this to see the HTML content of the page in the string variable source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz:\n",
    "\n",
    "1. is the word 'Alice' in source?\n",
    "2. count the occurence of the word 'soup'\n",
    "3. At what index occurs the string: 'COVID-19'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "50\n",
      "7309\n"
     ]
    }
   ],
   "source": [
    "## is 'Alice' in source?\n",
    "print(\"Alice\" in source)\n",
    "\n",
    "## count the occurence of the word 'soup'\n",
    "print(source.count('Soup'))\n",
    "\n",
    "## At what index occurs the string: 'COVID-19'?\n",
    "position = source.find('COVID-19')\n",
    "print(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COVID-19\n"
     ]
    }
   ],
   "source": [
    "## Check I got this right\n",
    "print(source[position:position+len('COVID-19')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beautiful Soup\n",
    "\n",
    "* parses html code\n",
    "* makes life a load easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/transitional.dtd\">\n",
      "<html>\n",
      "<head>\n",
      "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "<title>Beautiful Soup: We called him Tortoise because he taught us.</title>\n",
      "<link href=\"mailto:leonardr@segfault.org\" rev=\"made\"/>\n",
      "<link href=\"/nb/themes/Default/nb.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<meta content=\"Beautiful Soup: a library designed for screen-scraping HTML and XML.\" name=\"Description\"/>\n",
      "<meta content=\"Markov Approximation 1.4 (module: leonardr)\" name=\"generator\"/>\n",
      "<meta content=\"Leonard Richardson\" name=\"author\"/>\n",
      "</head>\n",
      "<body alink=\"red\" bgcolor=\"white\" link=\"blue\" text=\"black\" vlink=\"660066\">\n",
      "<style>\n",
      "#tidelift { }\n",
      "\n",
      "#tidelift a {\n",
      " border: 1px solid #666666;\n",
      " margin-left: auto;\n",
      " padding: 10px;\n",
      " text-decoration: none;\n",
      "}\n",
      "\n",
      "#tidelift .cta {\n",
      " background: url(\"tidelift.svg\") no-repeat;\n",
      " padding-left: 30px;\n",
      "}\n",
      "</style>\n",
      "<img align=\"right\" src=\"10.1.jpg\" width=\"250\"/><br/>\n",
      "<p>[ <a href=\"#Download\">Download</a> | <a href=\"bs4/doc/\">Documentation</a> | <a href=\"#HallOfFame\">Hall of Fame</a> | <a href=\"enterprise.html\">For enterprise</a> | <a href=\"https://code.launchpad.net/beautifulsoup\">Source</a> | <a href=\"https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG\">Changelog</a> | <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">Discussion group</a>  | <a href=\"zine/\">Zine</a> ]</p>\n",
      "<div align=\"center\">\n",
      "<a href=\"bs4/download/\"><h1>Beautiful Soup</h1></a>\n",
      "</div>\n",
      "<p>You didn't write that awful page. You're just trying to get some\n",
      "data out of it. Beautiful Soup is here to help. Since 2004, it's been\n",
      "saving programmers hours or days of work on quick-turnaround\n",
      "screen scraping projects.</p>\n",
      "<p>Beautiful Soup is a Python library designed for quick turnaround\n",
      "projects like screen-scraping. Three features make it powerful:\n",
      "\n",
      "</p><ol>\n",
      "<li>Beautiful Soup provides a few simple methods and Pythonic idioms\n",
      "for navigating, searching, and modifying a parse tree: a toolkit for\n",
      "dissecting a document and extracting what you need. It doesn't take\n",
      "much code to write an application\n",
      "\n",
      "</li><li>Beautiful Soup automatically converts incoming documents to\n",
      "Unicode and outgoing documents to UTF-8. You don't have to think\n",
      "about encodings, unless the document doesn't specify an encoding and\n",
      "Beautiful Soup can't detect one. Then you just have to specify the\n",
      "original encoding.\n",
      "\n",
      "</li><li>Beautiful Soup sits on top of popular Python parsers like <a href=\"http://lxml.de/\">lxml</a> and <a href=\"http://code.google.com/p/html5lib/\">html5lib</a>, allowing you\n",
      "to try out different parsing strategies or trade speed for\n",
      "flexibility.\n",
      "\n",
      "</li></ol>\n",
      "<p>Beautiful Soup parses anything you give it, and does the tree\n",
      "traversal stuff for you. You can tell it \"Find all the links\", or\n",
      "\"Find all the links of class <tt>externalLink</tt>\", or \"Find all the\n",
      "links whose urls match \"foo.com\", or \"Find the table heading that's\n",
      "got bold text, then give me that text.\"\n",
      "\n",
      "</p><p>Valuable data that was once locked up in poorly-designed websites\n",
      "is now within your reach. Projects that would have taken hours take\n",
      "only minutes with Beautiful Soup.\n",
      "\n",
      "</p><p>Interested? <a href=\"bs4/doc/\">Read more.</a>\n",
      "</p><h3>Getting and giving support</h3>\n",
      "<div align=\"center\" id=\"tidelift\">\n",
      "<a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=enterprise\" target=\"_blank\">\n",
      "<span class=\"cta\">\n",
      "  Beautiful Soup for enterprise available via Tidelift\n",
      " </span>\n",
      "</a>\n",
      "</div>\n",
      "<p>If you have questions, send them to <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">the discussion\n",
      "group</a>. If you find a bug, <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file it on Launchpad</a>. If it's a security vulnerability, report it confidentially through <a href=\"https://tidelift.com/security\">Tidelift</a>.</p>\n",
      "<p>If you use Beautiful Soup as part of your work, please consider a <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=website\">Tidelift subscription</a>. This will support many of the free software projects your organization depends on, not just Beautiful Soup.\n",
      "\n",
      "\n",
      "</p><p>If Beautiful Soup is useful to you on a personal level, you might like to read <a href=\"zine/\"><i>Tool Safety</i></a>, a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!</p>\n",
      "<a name=\"Download\"><h2>Download Beautiful Soup</h2></a>\n",
      "<p>The current release is <a href=\"bs4/download/\">Beautiful Soup\n",
      "4.9.0</a> (April 5, 2020). You can install Beautiful Soup 4 with\n",
      "<code>pip install beautifulsoup4</code>.\n",
      "\n",
      "</p><p>In Debian and Ubuntu, Beautiful Soup is available as the\n",
      "<code>python-bs4</code> package (for Python 2) or the\n",
      "<code>python3-bs4</code> package (for Python 3). In Fedora it's\n",
      "available as the <code>python-beautifulsoup4</code> package.\n",
      "\n",
      "</p><p>Beautiful Soup is licensed under the MIT license, so you can also\n",
      "download the tarball, drop the <code>bs4/</code> directory into almost\n",
      "any Python application (or into your library path) and start using it\n",
      "immediately. (If you want to do this under Python 3, you will need to\n",
      "manually convert the code using <code>2to3</code>.)\n",
      "\n",
      "</p><p>Beautiful Soup 4 works on both Python 2 (2.7+) and Python\n",
      "3. Support for Python 2 will be discontinued on or after December 31,\n",
      "2020—one year after the Python 2 sunsetting date.\n",
      "\n",
      "</p><h3>Beautiful Soup 3</h3>\n",
      "<p>Beautiful Soup 3 was the official release line of Beautiful Soup\n",
      "from May 2006 to March 2012. It does not support Python 3 and it will\n",
      "be discontinued on or after December 31, 2020—one year after the\n",
      "Python 2 sunsetting date. If you have any active projects using\n",
      "Beautiful Soup 3, you should migrate to Beautiful Soup 4 as part of\n",
      "your Python 3 conversion.\n",
      "\n",
      "</p><p><a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">Here's\n",
      "the Beautiful Soup 3 documentation.</a>\n",
      "</p><p>The current and hopefully final release of Beautiful Soup 3 is <a href=\"download/3.x/BeautifulSoup-3.2.2.tar.gz\">3.2.2</a> (October 5,\n",
      "2019). It's the <code>BeautifulSoup</code> package on pip. It's also\n",
      "available as <code>python-beautifulsoup</code> in Debian and Ubuntu,\n",
      "and as <code>python-BeautifulSoup</code> in Fedora.\n",
      "\n",
      "</p><p>Once Beautiful Soup 3 is discontinued, these package names will be available for use by a more recent version of Beautiful Soup.\n",
      "\n",
      "</p><p>Beautiful Soup 3, like Beautiful Soup 4, is <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&amp;utm_medium=referral&amp;utm_campaign=website\">supported through Tidelift</a>.</p>\n",
      "<a name=\"HallOfFame\"><h2>Hall of Fame</h2></a>\n",
      "<p>Over the years, Beautiful Soup has been used in hundreds of\n",
      "different projects. There's no way I can list them all, but I want to\n",
      "highlight a few high-profile projects. Beautiful Soup isn't what makes\n",
      "these projects interesting, but it did make their completion easier:\n",
      "\n",
      "</p><ul>\n",
      "<li><a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\"Movable\n",
      " Type\"</a>, a work of digital art on display in the lobby of the New\n",
      " York Times building, uses Beautiful Soup to scrape news feeds.\n",
      "\n",
      "</li><li>Jiabao Lin's <a href=\"https://github.com/BlankerL/DXY-COVID-19-Crawler\">DXY-COVID-19-Crawler</a>\n",
      "uses Beautiful Soup to scrape a Chinese medical site for information\n",
      "about COVID-19, making it easier for researchers to track the spread\n",
      "of the virus. (Source: <a href=\"https://blog.tidelift.com/how-open-source-software-is-fighting-covid-19\">\"How open source software is fighting COVID-19\"</a>)\n",
      "\n",
      "</li><li>Reddit uses Beautiful Soup to <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\n",
      "a page that's been linked to and find a representative image</a>.\n",
      "\n",
      "</li><li>Alexander Harrowell uses Beautiful Soup to <a href=\"http://www.harrowell.org.uk/viktormap.html\">track the business\n",
      " activities</a> of an arms merchant.\n",
      "\n",
      "</li><li>The developers of Python itself used Beautiful Soup to <a href=\"http://svn.python.org/view/tracker/importer/\">migrate the Python\n",
      "bug tracker from Sourceforge to Roundup</a>.\n",
      "\n",
      "</li><li>The <a href=\"http://www2.ljworld.com/\">Lawrence Journal-World</a>\n",
      "uses Beautiful Soup to <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">gather\n",
      "statewide election results</a>.\n",
      "\n",
      "</li><li>The <a href=\"http://esrl.noaa.gov/gsd/fab/\">NOAA's Forecast\n",
      "Applications Branch</a> uses Beautiful Soup in <a href=\"http://laps.noaa.gov/topograbber/\">TopoGrabber</a>, a script for\n",
      "downloading \"high resolution USGS datasets.\"\n",
      "\n",
      "</li></ul>\n",
      "<p>If you've used Beautiful Soup in a project you'd like me to know\n",
      "about, please do send email to me or <a href=\"http://groups.google.com/group/beautifulsoup/\">the discussion\n",
      "group</a>.\n",
      "\n",
      "</p><h2>Development</h2>\n",
      "<p>Development happens at <a href=\"https://launchpad.net/beautifulsoup\">Launchpad</a>. You can <a href=\"https://code.launchpad.net/beautifulsoup/\">get the source\n",
      "code</a> or <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file\n",
      "bugs</a>.</p><hr/><table><tr><td valign=\"top\">\n",
      "<p>This document (<a href=\"/source/software/BeautifulSoup/index.bhtml\">source</a>) is part of Crummy, the webspace of <a href=\"/self/\">Leonard Richardson</a> (<a href=\"/self/contact.html\">contact information</a>). It was last modified on Monday, April 06 2020, 17:23:04 Nowhere Standard Time and last built on Wednesday, April 22 2020, 11:00:01 Nowhere Standard Time.</p><p></p><table class=\"licenseText\"><tr><td><a href=\"http://creativecommons.org/licenses/by-sa/2.0/\"><img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/></a></td><td valign=\"top\">Crummy is © 1996-2020 Leonard Richardson. Unless otherwise noted, all text licensed under a <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Creative Commons License</a>.</td></tr></table><!--<rdf:RDF xmlns=\"http://web.resource.org/cc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"><Work rdf:about=\"http://www.crummy.com/\"><dc:title>Crummy: The Site</dc:title><dc:rights><Agent><dc:title>Crummy: the Site</dc:title></Agent></dc:rights><dc:format>text/html</dc:format><license rdf:resource=http://creativecommons.org/licenses/by-sa/2.0//></Work><License rdf:about=\"http://creativecommons.org/licenses/by-sa/2.0/\"></License></rdf:RDF>--></td><td valign=\"top\"><p><b>Document tree:</b>\n",
      "</p><dl><dd><a href=\"http://www.crummy.com/\">http://www.crummy.com/</a><dl><dd><a href=\"http://www.crummy.com/software/\">software/</a><dl><dd><a href=\"http://www.crummy.com/software/BeautifulSoup/\">BeautifulSoup/</a></dd></dl>\n",
      "</dd></dl>\n",
      "</dd></dl>\n",
      "\n",
      "\n",
      "Site Search:\n",
      "\n",
      "<form action=\"/search/\" method=\"get\">\n",
      "<input maxlength=\"255\" name=\"q\" type=\"text\" value=\"\"/>\n",
      "</form>\n",
      "</td>\n",
      "</tr>\n",
      "</table>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "\n",
      " \n",
      " \n",
      " AND PRETTIFIED! \n",
      " \n",
      " \n",
      "\n",
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/transitional.dtd\">\n",
      "<html>\n",
      " <head>\n",
      "  <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "  <title>\n",
      "   Beautiful Soup: We called him Tortoise because he taught us.\n",
      "  </title>\n",
      "  <link href=\"mailto:leonardr@segfault.org\" rev=\"made\"/>\n",
      "  <link href=\"/nb/themes/Default/nb.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "  <meta content=\"Beautiful Soup: a library designed for screen-scraping HTML and XML.\" name=\"Description\"/>\n",
      "  <meta content=\"Markov Approximation 1.4 (module: leonardr)\" name=\"generator\"/>\n",
      "  <meta content=\"Leonard Richardson\" name=\"author\"/>\n",
      " </head>\n",
      " <body alink=\"red\" bgcolor=\"white\" link=\"blue\" text=\"black\" vlink=\"660066\">\n",
      "  <style>\n",
      "   #tidelift { }\n",
      "\n",
      "#tidelift a {\n",
      " border: 1px solid #666666;\n",
      " margin-left: auto;\n",
      " padding: 10px;\n",
      " text-decoration: none;\n",
      "}\n",
      "\n",
      "#tidelift .cta {\n",
      " background: url(\"tidelift.svg\") no-repeat;\n",
      " padding-left: 30px;\n",
      "}\n",
      "  </style>\n",
      "  <img align=\"right\" src=\"10.1.jpg\" width=\"250\"/>\n",
      "  <br/>\n",
      "  <p>\n",
      "   [\n",
      "   <a href=\"#Download\">\n",
      "    Download\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"bs4/doc/\">\n",
      "    Documentation\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"#HallOfFame\">\n",
      "    Hall of Fame\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"enterprise.html\">\n",
      "    For enterprise\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"https://code.launchpad.net/beautifulsoup\">\n",
      "    Source\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG\">\n",
      "    Changelog\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">\n",
      "    Discussion group\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"zine/\">\n",
      "    Zine\n",
      "   </a>\n",
      "   ]\n",
      "  </p>\n",
      "  <div align=\"center\">\n",
      "   <a href=\"bs4/download/\">\n",
      "    <h1>\n",
      "     Beautiful Soup\n",
      "    </h1>\n",
      "   </a>\n",
      "  </div>\n",
      "  <p>\n",
      "   You didn't write that awful page. You're just trying to get some\n",
      "data out of it. Beautiful Soup is here to help. Since 2004, it's been\n",
      "saving programmers hours or days of work on quick-turnaround\n",
      "screen scraping projects.\n",
      "  </p>\n",
      "  <p>\n",
      "   Beautiful Soup is a Python library designed for quick turnaround\n",
      "projects like screen-scraping. Three features make it powerful:\n",
      "  </p>\n",
      "  <ol>\n",
      "   <li>\n",
      "    Beautiful Soup provides a few simple methods and Pythonic idioms\n",
      "for navigating, searching, and modifying a parse tree: a toolkit for\n",
      "dissecting a document and extracting what you need. It doesn't take\n",
      "much code to write an application\n",
      "   </li>\n",
      "   <li>\n",
      "    Beautiful Soup automatically converts incoming documents to\n",
      "Unicode and outgoing documents to UTF-8. You don't have to think\n",
      "about encodings, unless the document doesn't specify an encoding and\n",
      "Beautiful Soup can't detect one. Then you just have to specify the\n",
      "original encoding.\n",
      "   </li>\n",
      "   <li>\n",
      "    Beautiful Soup sits on top of popular Python parsers like\n",
      "    <a href=\"http://lxml.de/\">\n",
      "     lxml\n",
      "    </a>\n",
      "    and\n",
      "    <a href=\"http://code.google.com/p/html5lib/\">\n",
      "     html5lib\n",
      "    </a>\n",
      "    , allowing you\n",
      "to try out different parsing strategies or trade speed for\n",
      "flexibility.\n",
      "   </li>\n",
      "  </ol>\n",
      "  <p>\n",
      "   Beautiful Soup parses anything you give it, and does the tree\n",
      "traversal stuff for you. You can tell it \"Find all the links\", or\n",
      "\"Find all the links of class\n",
      "   <tt>\n",
      "    externalLink\n",
      "   </tt>\n",
      "   \", or \"Find all the\n",
      "links whose urls match \"foo.com\", or \"Find the table heading that's\n",
      "got bold text, then give me that text.\"\n",
      "  </p>\n",
      "  <p>\n",
      "   Valuable data that was once locked up in poorly-designed websites\n",
      "is now within your reach. Projects that would have taken hours take\n",
      "only minutes with Beautiful Soup.\n",
      "  </p>\n",
      "  <p>\n",
      "   Interested?\n",
      "   <a href=\"bs4/doc/\">\n",
      "    Read more.\n",
      "   </a>\n",
      "  </p>\n",
      "  <h3>\n",
      "   Getting and giving support\n",
      "  </h3>\n",
      "  <div align=\"center\" id=\"tidelift\">\n",
      "   <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=enterprise\" target=\"_blank\">\n",
      "    <span class=\"cta\">\n",
      "     Beautiful Soup for enterprise available via Tidelift\n",
      "    </span>\n",
      "   </a>\n",
      "  </div>\n",
      "  <p>\n",
      "   If you have questions, send them to\n",
      "   <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">\n",
      "    the discussion\n",
      "group\n",
      "   </a>\n",
      "   . If you find a bug,\n",
      "   <a href=\"https://bugs.launchpad.net/beautifulsoup/\">\n",
      "    file it on Launchpad\n",
      "   </a>\n",
      "   . If it's a security vulnerability, report it confidentially through\n",
      "   <a href=\"https://tidelift.com/security\">\n",
      "    Tidelift\n",
      "   </a>\n",
      "   .\n",
      "  </p>\n",
      "  <p>\n",
      "   If you use Beautiful Soup as part of your work, please consider a\n",
      "   <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=website\">\n",
      "    Tidelift subscription\n",
      "   </a>\n",
      "   . This will support many of the free software projects your organization depends on, not just Beautiful Soup.\n",
      "  </p>\n",
      "  <p>\n",
      "   If Beautiful Soup is useful to you on a personal level, you might like to read\n",
      "   <a href=\"zine/\">\n",
      "    <i>\n",
      "     Tool Safety\n",
      "    </i>\n",
      "   </a>\n",
      "   , a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!\n",
      "  </p>\n",
      "  <a name=\"Download\">\n",
      "   <h2>\n",
      "    Download Beautiful Soup\n",
      "   </h2>\n",
      "  </a>\n",
      "  <p>\n",
      "   The current release is\n",
      "   <a href=\"bs4/download/\">\n",
      "    Beautiful Soup\n",
      "4.9.0\n",
      "   </a>\n",
      "   (April 5, 2020). You can install Beautiful Soup 4 with\n",
      "   <code>\n",
      "    pip install beautifulsoup4\n",
      "   </code>\n",
      "   .\n",
      "  </p>\n",
      "  <p>\n",
      "   In Debian and Ubuntu, Beautiful Soup is available as the\n",
      "   <code>\n",
      "    python-bs4\n",
      "   </code>\n",
      "   package (for Python 2) or the\n",
      "   <code>\n",
      "    python3-bs4\n",
      "   </code>\n",
      "   package (for Python 3). In Fedora it's\n",
      "available as the\n",
      "   <code>\n",
      "    python-beautifulsoup4\n",
      "   </code>\n",
      "   package.\n",
      "  </p>\n",
      "  <p>\n",
      "   Beautiful Soup is licensed under the MIT license, so you can also\n",
      "download the tarball, drop the\n",
      "   <code>\n",
      "    bs4/\n",
      "   </code>\n",
      "   directory into almost\n",
      "any Python application (or into your library path) and start using it\n",
      "immediately. (If you want to do this under Python 3, you will need to\n",
      "manually convert the code using\n",
      "   <code>\n",
      "    2to3\n",
      "   </code>\n",
      "   .)\n",
      "  </p>\n",
      "  <p>\n",
      "   Beautiful Soup 4 works on both Python 2 (2.7+) and Python\n",
      "3. Support for Python 2 will be discontinued on or after December 31,\n",
      "2020—one year after the Python 2 sunsetting date.\n",
      "  </p>\n",
      "  <h3>\n",
      "   Beautiful Soup 3\n",
      "  </h3>\n",
      "  <p>\n",
      "   Beautiful Soup 3 was the official release line of Beautiful Soup\n",
      "from May 2006 to March 2012. It does not support Python 3 and it will\n",
      "be discontinued on or after December 31, 2020—one year after the\n",
      "Python 2 sunsetting date. If you have any active projects using\n",
      "Beautiful Soup 3, you should migrate to Beautiful Soup 4 as part of\n",
      "your Python 3 conversion.\n",
      "  </p>\n",
      "  <p>\n",
      "   <a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">\n",
      "    Here's\n",
      "the Beautiful Soup 3 documentation.\n",
      "   </a>\n",
      "  </p>\n",
      "  <p>\n",
      "   The current and hopefully final release of Beautiful Soup 3 is\n",
      "   <a href=\"download/3.x/BeautifulSoup-3.2.2.tar.gz\">\n",
      "    3.2.2\n",
      "   </a>\n",
      "   (October 5,\n",
      "2019). It's the\n",
      "   <code>\n",
      "    BeautifulSoup\n",
      "   </code>\n",
      "   package on pip. It's also\n",
      "available as\n",
      "   <code>\n",
      "    python-beautifulsoup\n",
      "   </code>\n",
      "   in Debian and Ubuntu,\n",
      "and as\n",
      "   <code>\n",
      "    python-BeautifulSoup\n",
      "   </code>\n",
      "   in Fedora.\n",
      "  </p>\n",
      "  <p>\n",
      "   Once Beautiful Soup 3 is discontinued, these package names will be available for use by a more recent version of Beautiful Soup.\n",
      "  </p>\n",
      "  <p>\n",
      "   Beautiful Soup 3, like Beautiful Soup 4, is\n",
      "   <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&amp;utm_medium=referral&amp;utm_campaign=website\">\n",
      "    supported through Tidelift\n",
      "   </a>\n",
      "   .\n",
      "  </p>\n",
      "  <a name=\"HallOfFame\">\n",
      "   <h2>\n",
      "    Hall of Fame\n",
      "   </h2>\n",
      "  </a>\n",
      "  <p>\n",
      "   Over the years, Beautiful Soup has been used in hundreds of\n",
      "different projects. There's no way I can list them all, but I want to\n",
      "highlight a few high-profile projects. Beautiful Soup isn't what makes\n",
      "these projects interesting, but it did make their completion easier:\n",
      "  </p>\n",
      "  <ul>\n",
      "   <li>\n",
      "    <a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\n",
      "     \"Movable\n",
      " Type\"\n",
      "    </a>\n",
      "    , a work of digital art on display in the lobby of the New\n",
      " York Times building, uses Beautiful Soup to scrape news feeds.\n",
      "   </li>\n",
      "   <li>\n",
      "    Jiabao Lin's\n",
      "    <a href=\"https://github.com/BlankerL/DXY-COVID-19-Crawler\">\n",
      "     DXY-COVID-19-Crawler\n",
      "    </a>\n",
      "    uses Beautiful Soup to scrape a Chinese medical site for information\n",
      "about COVID-19, making it easier for researchers to track the spread\n",
      "of the virus. (Source:\n",
      "    <a href=\"https://blog.tidelift.com/how-open-source-software-is-fighting-covid-19\">\n",
      "     \"How open source software is fighting COVID-19\"\n",
      "    </a>\n",
      "    )\n",
      "   </li>\n",
      "   <li>\n",
      "    Reddit uses Beautiful Soup to\n",
      "    <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">\n",
      "     parse\n",
      "a page that's been linked to and find a representative image\n",
      "    </a>\n",
      "    .\n",
      "   </li>\n",
      "   <li>\n",
      "    Alexander Harrowell uses Beautiful Soup to\n",
      "    <a href=\"http://www.harrowell.org.uk/viktormap.html\">\n",
      "     track the business\n",
      " activities\n",
      "    </a>\n",
      "    of an arms merchant.\n",
      "   </li>\n",
      "   <li>\n",
      "    The developers of Python itself used Beautiful Soup to\n",
      "    <a href=\"http://svn.python.org/view/tracker/importer/\">\n",
      "     migrate the Python\n",
      "bug tracker from Sourceforge to Roundup\n",
      "    </a>\n",
      "    .\n",
      "   </li>\n",
      "   <li>\n",
      "    The\n",
      "    <a href=\"http://www2.ljworld.com/\">\n",
      "     Lawrence Journal-World\n",
      "    </a>\n",
      "    uses Beautiful Soup to\n",
      "    <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">\n",
      "     gather\n",
      "statewide election results\n",
      "    </a>\n",
      "    .\n",
      "   </li>\n",
      "   <li>\n",
      "    The\n",
      "    <a href=\"http://esrl.noaa.gov/gsd/fab/\">\n",
      "     NOAA's Forecast\n",
      "Applications Branch\n",
      "    </a>\n",
      "    uses Beautiful Soup in\n",
      "    <a href=\"http://laps.noaa.gov/topograbber/\">\n",
      "     TopoGrabber\n",
      "    </a>\n",
      "    , a script for\n",
      "downloading \"high resolution USGS datasets.\"\n",
      "   </li>\n",
      "  </ul>\n",
      "  <p>\n",
      "   If you've used Beautiful Soup in a project you'd like me to know\n",
      "about, please do send email to me or\n",
      "   <a href=\"http://groups.google.com/group/beautifulsoup/\">\n",
      "    the discussion\n",
      "group\n",
      "   </a>\n",
      "   .\n",
      "  </p>\n",
      "  <h2>\n",
      "   Development\n",
      "  </h2>\n",
      "  <p>\n",
      "   Development happens at\n",
      "   <a href=\"https://launchpad.net/beautifulsoup\">\n",
      "    Launchpad\n",
      "   </a>\n",
      "   . You can\n",
      "   <a href=\"https://code.launchpad.net/beautifulsoup/\">\n",
      "    get the source\n",
      "code\n",
      "   </a>\n",
      "   or\n",
      "   <a href=\"https://bugs.launchpad.net/beautifulsoup/\">\n",
      "    file\n",
      "bugs\n",
      "   </a>\n",
      "   .\n",
      "  </p>\n",
      "  <hr/>\n",
      "  <table>\n",
      "   <tr>\n",
      "    <td valign=\"top\">\n",
      "     <p>\n",
      "      This document (\n",
      "      <a href=\"/source/software/BeautifulSoup/index.bhtml\">\n",
      "       source\n",
      "      </a>\n",
      "      ) is part of Crummy, the webspace of\n",
      "      <a href=\"/self/\">\n",
      "       Leonard Richardson\n",
      "      </a>\n",
      "      (\n",
      "      <a href=\"/self/contact.html\">\n",
      "       contact information\n",
      "      </a>\n",
      "      ). It was last modified on Monday, April 06 2020, 17:23:04 Nowhere Standard Time and last built on Wednesday, April 22 2020, 11:00:01 Nowhere Standard Time.\n",
      "     </p>\n",
      "     <p>\n",
      "     </p>\n",
      "     <table class=\"licenseText\">\n",
      "      <tr>\n",
      "       <td>\n",
      "        <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">\n",
      "         <img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/>\n",
      "        </a>\n",
      "       </td>\n",
      "       <td valign=\"top\">\n",
      "        Crummy is © 1996-2020 Leonard Richardson. Unless otherwise noted, all text licensed under a\n",
      "        <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">\n",
      "         Creative Commons License\n",
      "        </a>\n",
      "        .\n",
      "       </td>\n",
      "      </tr>\n",
      "     </table>\n",
      "     <!--<rdf:RDF xmlns=\"http://web.resource.org/cc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"><Work rdf:about=\"http://www.crummy.com/\"><dc:title>Crummy: The Site</dc:title><dc:rights><Agent><dc:title>Crummy: the Site</dc:title></Agent></dc:rights><dc:format>text/html</dc:format><license rdf:resource=http://creativecommons.org/licenses/by-sa/2.0//></Work><License rdf:about=\"http://creativecommons.org/licenses/by-sa/2.0/\"></License></rdf:RDF>-->\n",
      "    </td>\n",
      "    <td valign=\"top\">\n",
      "     <p>\n",
      "      <b>\n",
      "       Document tree:\n",
      "      </b>\n",
      "     </p>\n",
      "     <dl>\n",
      "      <dd>\n",
      "       <a href=\"http://www.crummy.com/\">\n",
      "        http://www.crummy.com/\n",
      "       </a>\n",
      "       <dl>\n",
      "        <dd>\n",
      "         <a href=\"http://www.crummy.com/software/\">\n",
      "          software/\n",
      "         </a>\n",
      "         <dl>\n",
      "          <dd>\n",
      "           <a href=\"http://www.crummy.com/software/BeautifulSoup/\">\n",
      "            BeautifulSoup/\n",
      "           </a>\n",
      "          </dd>\n",
      "         </dl>\n",
      "        </dd>\n",
      "       </dl>\n",
      "      </dd>\n",
      "     </dl>\n",
      "     Site Search:\n",
      "     <form action=\"/search/\" method=\"get\">\n",
      "      <input maxlength=\"255\" name=\"q\" type=\"text\" value=\"\"/>\n",
      "     </form>\n",
      "    </td>\n",
      "   </tr>\n",
      "  </table>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# turns source into a bs4 object\n",
    "soup = bs4.BeautifulSoup(source)\n",
    "\n",
    "print(soup)\n",
    "print('\\n \\n \\n AND PRETTIFIED! \\n \\n \\n')\n",
    "print(soup.prettify()) # so much more readable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"#Download\">Download</a>,\n",
       " <a href=\"bs4/doc/\">Documentation</a>,\n",
       " <a href=\"#HallOfFame\">Hall of Fame</a>,\n",
       " <a href=\"enterprise.html\">For enterprise</a>,\n",
       " <a href=\"https://code.launchpad.net/beautifulsoup\">Source</a>,\n",
       " <a href=\"https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG\">Changelog</a>,\n",
       " <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">Discussion group</a>,\n",
       " <a href=\"zine/\">Zine</a>,\n",
       " <a href=\"bs4/download/\"><h1>Beautiful Soup</h1></a>,\n",
       " <a href=\"http://lxml.de/\">lxml</a>,\n",
       " <a href=\"http://code.google.com/p/html5lib/\">html5lib</a>,\n",
       " <a href=\"bs4/doc/\">Read more.</a>,\n",
       " <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=enterprise\" target=\"_blank\">\n",
       " <span class=\"cta\">\n",
       "   Beautiful Soup for enterprise available via Tidelift\n",
       "  </span>\n",
       " </a>,\n",
       " <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">the discussion\n",
       " group</a>,\n",
       " <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file it on Launchpad</a>,\n",
       " <a href=\"https://tidelift.com/security\">Tidelift</a>,\n",
       " <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=website\">Tidelift subscription</a>,\n",
       " <a href=\"zine/\"><i>Tool Safety</i></a>,\n",
       " <a name=\"Download\"><h2>Download Beautiful Soup</h2></a>,\n",
       " <a href=\"bs4/download/\">Beautiful Soup\n",
       " 4.9.0</a>,\n",
       " <a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">Here's\n",
       " the Beautiful Soup 3 documentation.</a>,\n",
       " <a href=\"download/3.x/BeautifulSoup-3.2.2.tar.gz\">3.2.2</a>,\n",
       " <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&amp;utm_medium=referral&amp;utm_campaign=website\">supported through Tidelift</a>,\n",
       " <a name=\"HallOfFame\"><h2>Hall of Fame</h2></a>,\n",
       " <a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\"Movable\n",
       "  Type\"</a>,\n",
       " <a href=\"https://github.com/BlankerL/DXY-COVID-19-Crawler\">DXY-COVID-19-Crawler</a>,\n",
       " <a href=\"https://blog.tidelift.com/how-open-source-software-is-fighting-covid-19\">\"How open source software is fighting COVID-19\"</a>,\n",
       " <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\n",
       " a page that's been linked to and find a representative image</a>,\n",
       " <a href=\"http://www.harrowell.org.uk/viktormap.html\">track the business\n",
       "  activities</a>,\n",
       " <a href=\"http://svn.python.org/view/tracker/importer/\">migrate the Python\n",
       " bug tracker from Sourceforge to Roundup</a>,\n",
       " <a href=\"http://www2.ljworld.com/\">Lawrence Journal-World</a>,\n",
       " <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">gather\n",
       " statewide election results</a>,\n",
       " <a href=\"http://esrl.noaa.gov/gsd/fab/\">NOAA's Forecast\n",
       " Applications Branch</a>,\n",
       " <a href=\"http://laps.noaa.gov/topograbber/\">TopoGrabber</a>,\n",
       " <a href=\"http://groups.google.com/group/beautifulsoup/\">the discussion\n",
       " group</a>,\n",
       " <a href=\"https://launchpad.net/beautifulsoup\">Launchpad</a>,\n",
       " <a href=\"https://code.launchpad.net/beautifulsoup/\">get the source\n",
       " code</a>,\n",
       " <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file\n",
       " bugs</a>,\n",
       " <a href=\"/source/software/BeautifulSoup/index.bhtml\">source</a>,\n",
       " <a href=\"/self/\">Leonard Richardson</a>,\n",
       " <a href=\"/self/contact.html\">contact information</a>,\n",
       " <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\"><img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/></a>,\n",
       " <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Creative Commons License</a>,\n",
       " <a href=\"http://www.crummy.com/\">http://www.crummy.com/</a>,\n",
       " <a href=\"http://www.crummy.com/software/\">software/</a>,\n",
       " <a href=\"http://www.crummy.com/software/BeautifulSoup/\">BeautifulSoup/</a>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'The findAll method traverses the tree, starting at the given point, and finds all the Tag and NavigableString objects that match the criteria you give.'\n",
    "soup.findAll('a') # this will return all links with attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Examples:\n",
    "\n",
    "Here we want to extract the links from the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#Download',\n",
       " 'bs4/doc/',\n",
       " '#HallOfFame',\n",
       " 'enterprise.html',\n",
       " 'https://code.launchpad.net/beautifulsoup',\n",
       " 'https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG',\n",
       " 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n",
       " 'zine/',\n",
       " 'bs4/download/',\n",
       " 'http://lxml.de/',\n",
       " 'http://code.google.com/p/html5lib/',\n",
       " 'bs4/doc/',\n",
       " 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=enterprise',\n",
       " 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n",
       " 'https://bugs.launchpad.net/beautifulsoup/',\n",
       " 'https://tidelift.com/security',\n",
       " 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=website',\n",
       " 'zine/',\n",
       " None,\n",
       " 'bs4/download/',\n",
       " 'http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html',\n",
       " 'download/3.x/BeautifulSoup-3.2.2.tar.gz',\n",
       " 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&utm_medium=referral&utm_campaign=website',\n",
       " None,\n",
       " 'http://www.nytimes.com/2007/10/25/arts/design/25vide.html',\n",
       " 'https://github.com/BlankerL/DXY-COVID-19-Crawler',\n",
       " 'https://blog.tidelift.com/how-open-source-software-is-fighting-covid-19',\n",
       " 'https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py',\n",
       " 'http://www.harrowell.org.uk/viktormap.html',\n",
       " 'http://svn.python.org/view/tracker/importer/',\n",
       " 'http://www2.ljworld.com/',\n",
       " 'http://www.b-list.org/weblog/2010/nov/02/news-done-broke/',\n",
       " 'http://esrl.noaa.gov/gsd/fab/',\n",
       " 'http://laps.noaa.gov/topograbber/',\n",
       " 'http://groups.google.com/group/beautifulsoup/',\n",
       " 'https://launchpad.net/beautifulsoup',\n",
       " 'https://code.launchpad.net/beautifulsoup/',\n",
       " 'https://bugs.launchpad.net/beautifulsoup/',\n",
       " '/source/software/BeautifulSoup/index.bhtml',\n",
       " '/self/',\n",
       " '/self/contact.html',\n",
       " 'http://creativecommons.org/licenses/by-sa/2.0/',\n",
       " 'http://creativecommons.org/licenses/by-sa/2.0/',\n",
       " 'http://www.crummy.com/',\n",
       " 'http://www.crummy.com/software/',\n",
       " 'http://www.crummy.com/software/BeautifulSoup/']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so let's create a variable of all of the links with attributes\n",
    "# this will only return the first occurence in the string:\n",
    "first_tag = soup.find('a')\n",
    "\n",
    "# then we pull the hred attributes:\n",
    "first_tag.get('href')\n",
    "\n",
    "# get all the links in the page:\n",
    "link_list = [l.get('href') for l in soup.findAll('a')]\n",
    "link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://code.launchpad.net/beautifulsoup',\n",
       " 'https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG',\n",
       " 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n",
       " 'http://lxml.de/',\n",
       " 'http://code.google.com/p/html5lib/',\n",
       " 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=enterprise',\n",
       " 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n",
       " 'https://bugs.launchpad.net/beautifulsoup/',\n",
       " 'https://tidelift.com/security',\n",
       " 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=website',\n",
       " 'http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html',\n",
       " 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&utm_medium=referral&utm_campaign=website',\n",
       " 'http://www.nytimes.com/2007/10/25/arts/design/25vide.html',\n",
       " 'https://github.com/BlankerL/DXY-COVID-19-Crawler',\n",
       " 'https://blog.tidelift.com/how-open-source-software-is-fighting-covid-19',\n",
       " 'https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py',\n",
       " 'http://www.harrowell.org.uk/viktormap.html',\n",
       " 'http://svn.python.org/view/tracker/importer/',\n",
       " 'http://www2.ljworld.com/',\n",
       " 'http://www.b-list.org/weblog/2010/nov/02/news-done-broke/',\n",
       " 'http://esrl.noaa.gov/gsd/fab/',\n",
       " 'http://laps.noaa.gov/topograbber/',\n",
       " 'http://groups.google.com/group/beautifulsoup/',\n",
       " 'https://launchpad.net/beautifulsoup',\n",
       " 'https://code.launchpad.net/beautifulsoup/',\n",
       " 'https://bugs.launchpad.net/beautifulsoup/',\n",
       " 'http://creativecommons.org/licenses/by-sa/2.0/',\n",
       " 'http://creativecommons.org/licenses/by-sa/2.0/',\n",
       " 'http://www.crummy.com/',\n",
       " 'http://www.crummy.com/software/',\n",
       " 'http://www.crummy.com/software/BeautifulSoup/']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's filter those objects out in the for loop\n",
    "external_links = []\n",
    "\n",
    "# write a loop to filter the links\n",
    "# if it is not None and starts with 'http' we are happy\n",
    "for l in link_list:\n",
    "    if l is not None and l[:4] == 'http':\n",
    "        external_links.append(l)\n",
    "        \n",
    "external_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://code.launchpad.net/beautifulsoup',\n",
       " 'https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG',\n",
       " 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n",
       " 'http://lxml.de/',\n",
       " 'http://code.google.com/p/html5lib/',\n",
       " 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=enterprise',\n",
       " 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n",
       " 'https://bugs.launchpad.net/beautifulsoup/',\n",
       " 'https://tidelift.com/security',\n",
       " 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=website',\n",
       " 'http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html',\n",
       " 'https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&utm_medium=referral&utm_campaign=website',\n",
       " 'http://www.nytimes.com/2007/10/25/arts/design/25vide.html',\n",
       " 'https://github.com/BlankerL/DXY-COVID-19-Crawler',\n",
       " 'https://blog.tidelift.com/how-open-source-software-is-fighting-covid-19',\n",
       " 'https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py',\n",
       " 'http://www.harrowell.org.uk/viktormap.html',\n",
       " 'http://svn.python.org/view/tracker/importer/',\n",
       " 'http://www2.ljworld.com/',\n",
       " 'http://www.b-list.org/weblog/2010/nov/02/news-done-broke/',\n",
       " 'http://esrl.noaa.gov/gsd/fab/',\n",
       " 'http://laps.noaa.gov/topograbber/',\n",
       " 'http://groups.google.com/group/beautifulsoup/',\n",
       " 'https://launchpad.net/beautifulsoup',\n",
       " 'https://code.launchpad.net/beautifulsoup/',\n",
       " 'https://bugs.launchpad.net/beautifulsoup/',\n",
       " 'http://creativecommons.org/licenses/by-sa/2.0/',\n",
       " 'http://creativecommons.org/licenses/by-sa/2.0/',\n",
       " 'http://www.crummy.com/',\n",
       " 'http://www.crummy.com/software/',\n",
       " 'http://www.crummy.com/software/BeautifulSoup/']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and we can put this in a list comprehension as well, it almost reads like \n",
    "# a sentence.\n",
    "\n",
    "[l for l in link_list if l is not None and l.startswith('http')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Side-note: List comprehension is something I've come accross but not used extensively - more detail here: https://www.pythonforbeginners.com/basics/list-comprehensions-in-python"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the Tree\n",
    "\n",
    "The HTML tree:\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Useful document for understanding the different elements in HTML: https://www.w3.org/TR/html401/struct/global.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I'm going to go off-syllabus here\n",
    "#### I want to scrape Rightmove for potential properties for me and my mates to move into once this whole COVID thing is over!\n",
    "I'll start simple and probably build this out over time!\n",
    "\n",
    "@maksimKorzh's scraper here: https://github.com/maksimKorzh/one-time-scrapers/blob/master/scrapers/rightmove_scraper.py was a huge help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.rightmove.co.uk/property-to-rent/find.html?locationIdentifier=STATION%5E1400&minBedrooms=4&maxPrice=6000&minPrice=3000&radius=1.0&propertyTypes=&includeLetAgreed=false&mustHave=&dontShow=&furnishTypes=&keywords='\n",
    "source = request.urlopen(url).read().decode()\n",
    "soup = bs4.BeautifulSoup(source, 'lxml')\n",
    "pretty_soup = soup.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now the html has been parsed to lxml, I need to create the different component variables that I'm looking for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4 bedroom terraced house', '4 bedroom terraced house', '4 bedroom maisonette', '5 bedroom flat', '4 bedroom mews house', '4 bedroom house', '4 bedroom semi-detached house', '4 bedroom flat', '5 bedroom flat', '4 bedroom terraced house', '4 bedroom terraced house', '4 bedroom terraced house', '4 bedroom flat', '4 bedroom terraced house', '4 bedroom character property', '4 bedroom house', '4 bedroom terraced house', '4 bedroom house', '4 bedroom terraced house', '4 bedroom mews house', '4 bedroom house', '4 bedroom detached house', 'Property', 'Property', 'Property']\n",
      "\n",
      "['Stmathews Rd, Brixton, SW2', \"St Matthew's Road, Brixton Hill, London\", 'Burgate Court, London', 'Stockwell Green', 'Hazlewood Mews, London, SW9', 'Park Hill Clapham SW4', 'Kings Avenue, London, SW4', 'Aytoun Road, London, SW9', 'Edithna Road ', 'Welby Street, Camberwell, London, SE5', 'Sudbourne Road, Brixton', 'Torrens Road, Brixton', 'Aristotle Road, SW4', 'Stockwell Park Road, London, SW9', 'Hinton Road, London, SE24', 'Solon Road, SW2', 'Brockwell Park Row, SW2', 'Plato Road, London', 'Abbeville Road, Clapham', 'Barnwell Road, SW2', 'Mayall Road, Brixton, London, SE24', 'Branksome Road, Brixton', '', '', '']\n",
      "\n",
      "['0.45 miles from station', '0.45 miles from station', '0.13 miles from station', '0.45 miles from station', '0.71 miles from station', '0.91 miles from station', '0.80 miles from station', '0.41 miles from station', '0.56 miles from station', '0.85 miles from station', '0.37 miles from station', '0.49 miles from station', '0.76 miles from station', '0.81 miles from station', '0.56 miles from station', '0.53 miles from station', '0.92 miles from station', '0.56 miles from station', '0.97 miles from station', '0.39 miles from station', '0.42 miles from station', '0.62 miles from station']\n",
      "\n",
      "['We are proud to offer this delightful 4 bedroom, 2 bathroom terraced house in a great location. Available to move in from 15 April 2020, this property benefits from garden access. Property is off... ** Property Reference: 763526 **', 'Ideally located four bedroom house is perfect for sharers or a large family. This property comprises a large living area, separate kitchen, utility room, downstairs shower room and four double bedrooms! St Matthew´s Road perfectly located in close proximity to Brixton Station, meaning you c...', 'Seeking Prof. Sharers - 4 Double bed 2 Bath Top Spec - Be at London Victoria in 11 mins or Oxford Circus in 15 mins from stepping out of your front door Located 2 mins walk to Brixton National Rail and 3mins from Brixton tube station this property i...', 'This beautiful property boasts size, quality and location. This Victorian conversion, arranged over three floors and comprises of wooden flooring throughout, five double bedrooms, two bathrooms and stylish and contemporary living areas.', 'A stunning four-bedroom house with private garden and off street parking, situated in a gated mews development, just a short stroll from Clapham North station and the amenities of Clapham High Street', 'A stunning four/five bedroom freehold house with private garden, beautifully presented and located just moments from the wonderful Abbeville Village', 'A spacious and bright four-bedroom semi-detached house with large garden and off street parking, situated a short walk from both the Northern and Victoria Lines', \"SHORT LET! Fantastic four bed duplex maisonette. The property has a front garden in a quiet road, opposite a well-maintained pond. You're at a 5-minute walk to Stockwell Tube station, where you can catch Victoria and Northern lines.\", 'This truly stunning five bed roomed period house has been redecorated and refurbished to the highest of standard.Boasting three bathrooms, wooden floors, stylish fixtures and fittings and a beautiful scheduled easy to maintain patio garden.', 'Very well presented family house located in Camberwell just a short walk to Denmark Hill and Oval Underground Station. There are 3 floors, host to 4 bedrooms, 3 bathrooms and a small garden. 3 double bedrooms and 4th smaller single bedroom.', 'A substantial 1930’s terraced house on one of Brixton’s most desirable residential roads. The property features a large front reception room, separate kitchen, 4 double bedrooms (one slightly smaller than the others), a bathroom and a private garden. Ideally located, the house is moments from Bri...', 'A spacious four double bedroom house located in Brixton, offering a reception room, large bathroom, modern eat in kitchen with French doors onto a private rear garden.', 'LONG LET. ZERO DEPOSIT OPTION AVAILABLE. A fantastic modern four double bedroom apartment ideal for profesional sharers. The property benefits from four large double bedrooms, three bathrooms, living roomd and seperate modern kitchen. The property also benefits from a large private garden to the..', 'Extensively renovated and developed, immaculately presented four bedroom town house conveniently located just three minutes walk from Stockwell tube. Superb accommodation over four floors, and ben... ** Property Reference: 751689 **', '** NO REFERENCING FEES ** Available at the end of February is this newly built townhouse located conveniently between Brixton and Herne Hill. Offering four good sized bedrooms, a family bathroom, an en suite to the master bedroom and a downstairs cloakroom as well as a private decked g...', 'A charming example of a four double bedroom Victorian house between Clapham and Brixton', 'A beautiful four bed, three bath town house overlooking tranquil Brockwell Park.', 'A beautiful four double bedroom house close to both Clapham and Brixton.', 'A four bedroom two bathroom Victorian terraced house split over three floors. Newly refurbished with a private garden, this property is suitable for professional sharers.', 'Large four double bedroom house with a private garden in Brixton', 'Newly refurbished four double bedroom house located within walking distance of Brixton and Herne Hill. Double reception room, kitchen diner and two full sized bathrooms. Reclaimed pine flooring throughout the living spaces. Ideal for a family or 4 people sharing. ...', 'VERY SPECIAL. - AVAILABLE WITH DEPOSIT FREE OPTION. This beautifully well presented large and spacious four double bedroom house with garden.', '', '', '']\n",
      "\n",
      "<class 'datetime.date'>\n",
      "\n",
      "['by OpenRent, London', 'by Martin & Co, Streatham - Lettings and Sales', 'by Urban.co.uk, National', 'by Black Katz, London Bridge', 'by Marsh & Parsons, Clapham', 'by Kinleigh Folkard & Hayward - Lettings, Clapham', 'by Marsh & Parsons, Clapham', 'by Houst, London', 'by Black Katz, London Bridge', 'by Lavanda, London', 'by Eden Harper , Brixton', 'by Dexters, Clapham High Street', 'by Douglas & Gordon, Clapham Southside', 'by OpenRent, London', 'by Eaton Green Estate Agents, Camberwell', 'by Keating Estates, Clapham', 'by Keating Estates, Brixton', 'by Keating Estates, Clapham', 'by Jacksons Estate Agents, Clapham', 'by Keating Estates, Brixton', 'by Petermans, West Dulwich', 'by haart, Brixton - Lettings', '', '', '']\n",
      "\n",
      "['020 3322 3265', '020 3858 2715', '020 8012 4552', '020 8012 1690', '020 8012 4057', '020 3858 2400', '020 8012 4057', '020 8012 7036', '020 8012 1690', '020 3858 2772', '020 8012 3847', '020 7483 6364', '020 8012 3779', '020 3322 3265', '020 8012 4142', '020 8012 2330', '020 8012 9055', '020 8012 2330', '020 8012 0791', '020 8012 9055', '020 3858 2761', '020 8012 1473', '', '', '']\n",
      "\n",
      "['£3,000 pcm', '£3,000 pcm', '£3,250 pcm', '£3,835 pcm', '£3,445 pcm', '£3,650 pcm', '£3,445 pcm', '£3,550 pcm', '£4,498 pcm', '£3,012 pcm', '£3,198 pcm', '£3,501 pcm', '£3,683 pcm', '£4,900 pcm', '£3,200 pcm', '£3,510 pcm', '£3,445 pcm', '£3,380 pcm', '£3,750 pcm', '£3,250 pcm', '£3,700 pcm', '£3,250 pcm', '', '', '']\n",
      "\n",
      "['https://www.rightmove.co.uk/property-to-rent/property-78946597.html', 'https://www.rightmove.co.uk/property-to-rent/property-78939919.html', 'https://www.rightmove.co.uk/property-to-rent/property-91371155.html', 'https://www.rightmove.co.uk/property-to-rent/property-69571251.html', 'https://www.rightmove.co.uk/property-to-rent/property-78330154.html', 'https://www.rightmove.co.uk/property-to-rent/property-69496221.html', 'https://www.rightmove.co.uk/property-to-rent/property-78606799.html', 'https://www.rightmove.co.uk/property-to-rent/property-90792797.html', 'https://www.rightmove.co.uk/property-to-rent/property-69296988.html', 'https://www.rightmove.co.uk/property-to-rent/property-90767147.html', 'https://www.rightmove.co.uk/property-to-rent/property-78406369.html', 'https://www.rightmove.co.uk/property-to-rent/property-78401101.html', 'https://www.rightmove.co.uk/property-to-rent/property-90560207.html', 'https://www.rightmove.co.uk/property-to-rent/property-78337882.html', 'https://www.rightmove.co.uk/property-to-rent/property-78333196.html', 'https://www.rightmove.co.uk/property-to-rent/property-90586844.html', 'https://www.rightmove.co.uk/property-to-rent/property-90434222.html', 'https://www.rightmove.co.uk/property-to-rent/property-90433730.html', 'https://www.rightmove.co.uk/property-to-rent/property-90311705.html', 'https://www.rightmove.co.uk/property-to-rent/property-90291371.html', 'https://www.rightmove.co.uk/property-to-rent/property-78074293.html', 'https://www.rightmove.co.uk/property-to-rent/property-90121943.html', 'https://www.rightmove.co.uk', 'https://www.rightmove.co.uk', 'https://www.rightmove.co.uk']\n"
     ]
    }
   ],
   "source": [
    "# get the headline (i.e. the number of rooms and type of building):\n",
    "title = [title.text.strip() for title in soup.findAll('h2', {'class': 'propertyCard-title'})] # list comprehension woop! So I believe that the text attribute is specific to BS?\n",
    "print(title)\n",
    "print()\n",
    "\n",
    "# get the address:\n",
    "address = [address['content'] for address in soup.findAll('meta', {'itemprop': 'streetAddress'})] #need only the content element\n",
    "print(address)\n",
    "print()\n",
    "\n",
    "#get the number of miles from the station in question:\n",
    "miles = [miles.text.strip() for miles in soup.findAll('div', {'class': 'propertyCard-distance'})]\n",
    "print(miles)\n",
    "print()\n",
    "\n",
    "#get the property description:\n",
    "desc = [desc.text.strip() for desc in soup.findAll('span', {'itemprop':'description'})]\n",
    "print(desc)\n",
    "print()\n",
    "\n",
    "#get the date added to the site:\n",
    "dateadded = [dateadded.text.strip() for dateadded in soup.findAll('span', {'class': 'propertyCard-branchSummary-addedOrReduced'})]\n",
    "print(date)\n",
    "print()\n",
    "\n",
    "#get the estate agent's name:\n",
    "agent = [agent.text.strip() for agent in soup.findAll('span', {'class': 'propertyCard-branchSummary-branchName'})]\n",
    "print(agent)\n",
    "print()\n",
    "\n",
    "#get the agent's number:\n",
    "number = [number.text.strip() for number in soup.findAll('a', {'class': 'propertyCard-contactsPhoneNumber'})]\n",
    "print(number)\n",
    "print()\n",
    "\n",
    "#get the property's price:\n",
    "price = [price.text.strip() for price in soup.findAll('span', {'class': 'propertyCard-priceValue'})]\n",
    "print(price)\n",
    "print()\n",
    "\n",
    "#link to the property's page:\n",
    "link = ['https://www.rightmove.co.uk' + link['href'] for link in soup.findAll('a', {'class': 'propertyCard-headerLink'})]\n",
    "print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YASYASYASYAS it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "count = sum(1 for i in price if not i is '')\n",
    "print(count)\n",
    "\n",
    "for index in range(0, count):\n",
    "    results.append({\n",
    "        'date_added to file' : d.today().strftime(\"%d/%m/%Y\"), #https://www.programiz.com/python-programming/online-compiler/?ref=957b4f50\n",
    "        'title' : title[index],\n",
    "        'address' : address[index],\n",
    "        'miles from station' : miles[index],\n",
    "        'description' : desc[index],\n",
    "        'price' : price[index],\n",
    "        'date added/price changed' : dateadded[index],\n",
    "        'agent' : agent[index],\n",
    "        'agent phone number' : number[index],\n",
    "        'link to property' : link[index]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'date_added to file': '22/04/2020',\n",
       "  'title': '4 bedroom terraced house',\n",
       "  'address': 'Stmathews Rd, Brixton, SW2',\n",
       "  'miles from station': '0.45 miles from station',\n",
       "  'description': 'We are proud to offer this delightful 4 bedroom, 2 bathroom terraced house in a great location. Available to move in from 15 April 2020, this property benefits from garden access. Property is off... ** Property Reference: 763526 **',\n",
       "  'price': '£3,000 pcm',\n",
       "  'date added/price changed': 'Added on 15/04/2020',\n",
       "  'agent': 'by OpenRent, London',\n",
       "  'agent phone number': '020 3322 3265',\n",
       "  'link to property': 'https://www.rightmove.co.uk/property-to-rent/property-78946597.html'},\n",
       " {'date_added to file': '22/04/2020',\n",
       "  'title': '4 bedroom terraced house',\n",
       "  'address': \"St Matthew's Road, Brixton Hill, London\",\n",
       "  'miles from station': '0.45 miles from station',\n",
       "  'description': 'Ideally located four bedroom house is perfect for sharers or a large family. This property comprises a large living area, separate kitchen, utility room, downstairs shower room and four double bedrooms! St Matthew´s Road perfectly located in close proximity to Brixton Station, meaning you c...',\n",
       "  'price': '£3,000 pcm',\n",
       "  'date added/price changed': 'Added on 15/04/2020',\n",
       "  'agent': 'by Martin & Co, Streatham - Lettings and Sales',\n",
       "  'agent phone number': '020 3858 2715',\n",
       "  'link to property': 'https://www.rightmove.co.uk/property-to-rent/property-78939919.html'},\n",
       " {'date_added to file': '22/04/2020',\n",
       "  'title': '4 bedroom maisonette',\n",
       "  'address': 'Burgate Court, London',\n",
       "  'miles from station': '0.13 miles from station',\n",
       "  'description': 'Seeking Prof. Sharers - 4 Double bed 2 Bath Top Spec - Be at London Victoria in 11 mins or Oxford Circus in 15 mins from stepping out of your front door Located 2 mins walk to Brixton National Rail and 3mins from Brixton tube station this property i...',\n",
       "  'price': '£3,250 pcm',\n",
       "  'date added/price changed': 'Added on 13/04/2020',\n",
       "  'agent': 'by Urban.co.uk, National',\n",
       "  'agent phone number': '020 8012 4552',\n",
       "  'link to property': 'https://www.rightmove.co.uk/property-to-rent/property-91371155.html'},\n",
       " {'date_added to file': '22/04/2020',\n",
       "  'title': '5 bedroom flat',\n",
       "  'address': 'Stockwell Green',\n",
       "  'miles from station': '0.45 miles from station',\n",
       "  'description': 'This beautiful property boasts size, quality and location. This Victorian conversion, arranged over three floors and comprises of wooden flooring throughout, five double bedrooms, two bathrooms and stylish and contemporary living areas.',\n",
       "  'price': '£3,835 pcm',\n",
       "  'date added/price changed': 'Added on 09/04/2020',\n",
       "  'agent': 'by Black Katz, London Bridge',\n",
       "  'agent phone number': '020 8012 1690',\n",
       "  'link to property': 'https://www.rightmove.co.uk/property-to-rent/property-69571251.html'},\n",
       " {'date_added to file': '22/04/2020',\n",
       "  'title': '4 bedroom mews house',\n",
       "  'address': 'Hazlewood Mews, London, SW9',\n",
       "  'miles from station': '0.71 miles from station',\n",
       "  'description': 'A stunning four-bedroom house with private garden and off street parking, situated in a gated mews development, just a short stroll from Clapham North station and the amenities of Clapham High Street',\n",
       "  'price': '£3,445 pcm',\n",
       "  'date added/price changed': 'Reduced on 09/04/2020',\n",
       "  'agent': 'by Marsh & Parsons, Clapham',\n",
       "  'agent phone number': '020 8012 4057',\n",
       "  'link to property': 'https://www.rightmove.co.uk/property-to-rent/property-78330154.html'},\n",
       " {'date_added to file': '22/04/2020',\n",
       "  'title': '4 bedroom house',\n",
       "  'address': 'Park Hill Clapham SW4',\n",
       "  'miles from station': '0.91 miles from station',\n",
       "  'description': 'A stunning four/five bedroom freehold house with private garden, beautifully presented and located just moments from the wonderful Abbeville Village',\n",
       "  'price': '£3,650 pcm',\n",
       "  'date added/price changed': 'Added on 04/04/2020',\n",
       "  'agent': 'by Kinleigh Folkard & Hayward - Lettings, Clapham',\n",
       "  'agent phone number': '020 3858 2400',\n",
       "  'link to property': 'https://www.rightmove.co.uk/property-to-rent/property-69496221.html'},\n",
       " {'date_added to file': '22/04/2020',\n",
       "  'title': '4 bedroom semi-detached house',\n",
       "  'address': 'Kings Avenue, London, SW4',\n",
       "  'miles from station': '0.80 miles from station',\n",
       "  'description': 'A spacious and bright four-bedroom semi-detached house with large garden and off street parking, situated a short walk from both the Northern and Victoria Lines',\n",
       "  'price': '£3,445 pcm',\n",
       "  'date added/price changed': 'Added on 01/04/2020',\n",
       "  'agent': 'by Marsh & Parsons, Clapham',\n",
       "  'agent phone number': '020 8012 4057',\n",
       "  'link to property': 'https://www.rightmove.co.uk/property-to-rent/property-78606799.html'},\n",
       " {'date_added to file': '22/04/2020',\n",
       "  'title': '4 bedroom flat',\n",
       "  'address': 'Aytoun Road, London, SW9',\n",
       "  'miles from station': '0.41 miles from station',\n",
       "  'description': \"SHORT LET! Fantastic four bed duplex maisonette. The property has a front garden in a quiet road, opposite a well-maintained pond. You're at a 5-minute walk to Stockwell Tube station, where you can catch Victoria and Northern lines.\",\n",
       "  'price': '£3,550 pcm',\n",
       "  'date added/price changed': 'Added on 24/03/2020',\n",
       "  'agent': 'by Houst, London',\n",
       "  'agent phone number': '020 8012 7036',\n",
       "  'link to property': 'https://www.rightmove.co.uk/property-to-rent/property-90792797.html'},\n",
       " {'date_added to file': '22/04/2020',\n",
       "  'title': '5 bedroom flat',\n",
       "  'address': 'Edithna Road ',\n",
       "  'miles from station': '0.56 miles from station',\n",
       "  'description': 'This truly stunning five bed roomed period house has been redecorated and refurbished to the highest of standard.Boasting three bathrooms, wooden floors, stylish fixtures and fittings and a beautiful scheduled easy to maintain patio garden.',\n",
       "  'price': '£4,498 pcm',\n",
       "  'date added/price changed': 'Added on 24/03/2020',\n",
       "  'agent': 'by Black Katz, London Bridge',\n",
       "  'agent phone number': '020 8012 1690',\n",
       "  'link to property': 'https://www.rightmove.co.uk/property-to-rent/property-69296988.html'},\n",
       " {'date_added to file': '22/04/2020',\n",
       "  'title': '4 bedroom terraced house',\n",
       "  'address': 'Welby Street, Camberwell, London, SE5',\n",
       "  'miles from station': '0.85 miles from station',\n",
       "  'description': 'Very well presented family house located in Camberwell just a short walk to Denmark Hill and Oval Underground Station. There are 3 floors, host to 4 bedrooms, 3 bathrooms and a small garden. 3 double bedrooms and 4th smaller single bedroom.',\n",
       "  'price': '£3,012 pcm',\n",
       "  'date added/price changed': 'Added on 23/03/2020',\n",
       "  'agent': 'by Lavanda, London',\n",
       "  'agent phone number': '020 3858 2772',\n",
       "  'link to property': 'https://www.rightmove.co.uk/property-to-rent/property-90767147.html'},\n",
       " {'date_added to file': '22/04/2020',\n",
       "  'title': '4 bedroom terraced house',\n",
       "  'address': 'Sudbourne Road, Brixton',\n",
       "  'miles from station': '0.37 miles from station',\n",
       "  'description': 'A substantial 1930’s terraced house on one of Brixton’s most desirable residential roads. The property features a large front reception room, separate kitchen, 4 double bedrooms (one slightly smaller than the others), a bathroom and a private garden. Ideally located, the house is moments from Bri...',\n",
       "  'price': '£3,198 pcm',\n",
       "  'date added/price changed': 'Added on 23/03/2020',\n",
       "  'agent': 'by Eden Harper , Brixton',\n",
       "  'agent phone number': '020 8012 3847',\n",
       "  'link to property': 'https://www.rightmove.co.uk/property-to-rent/property-78406369.html'},\n",
       " {'date_added to file': '22/04/2020',\n",
       "  'title': '4 bedroom terraced house',\n",
       "  'address': 'Torrens Road, Brixton',\n",
       "  'miles from station': '0.49 miles from station',\n",
       "  'description': 'A spacious four double bedroom house located in Brixton, offering a reception room, large bathroom, modern eat in kitchen with French doors onto a private rear garden.',\n",
       "  'price': '£3,501 pcm',\n",
       "  'date added/price changed': 'Added on 23/03/2020',\n",
       "  'agent': 'by Dexters, Clapham High Street',\n",
       "  'agent phone number': '020 7483 6364',\n",
       "  'link to property': 'https://www.rightmove.co.uk/property-to-rent/property-78401101.html'},\n",
       " {'date_added to file': '22/04/2020',\n",
       "  'title': '4 bedroom flat',\n",
       "  'address': 'Aristotle Road, SW4',\n",
       "  'miles from station': '0.76 miles from station',\n",
       "  'description': 'LONG LET. ZERO DEPOSIT OPTION AVAILABLE. A fantastic modern four double bedroom apartment ideal for profesional sharers. The property benefits from four large double bedrooms, three bathrooms, living roomd and seperate modern kitchen. The property also benefits from a large private garden to the..',\n",
       "  'price': '£3,683 pcm',\n",
       "  'date added/price changed': 'Reduced on 23/03/2020',\n",
       "  'agent': 'by Douglas & Gordon, Clapham Southside',\n",
       "  'agent phone number': '020 8012 3779',\n",
       "  'link to property': 'https://www.rightmove.co.uk/property-to-rent/property-90560207.html'},\n",
       " {'date_added to file': '22/04/2020',\n",
       "  'title': '4 bedroom terraced house',\n",
       "  'address': 'Stockwell Park Road, London, SW9',\n",
       "  'miles from station': '0.81 miles from station',\n",
       "  'description': 'Extensively renovated and developed, immaculately presented four bedroom town house conveniently located just three minutes walk from Stockwell tube. Superb accommodation over four floors, and ben... ** Property Reference: 751689 **',\n",
       "  'price': '£4,900 pcm',\n",
       "  'date added/price changed': 'Added on 20/03/2020',\n",
       "  'agent': 'by OpenRent, London',\n",
       "  'agent phone number': '020 3322 3265',\n",
       "  'link to property': 'https://www.rightmove.co.uk/property-to-rent/property-78337882.html'},\n",
       " {'date_added to file': '22/04/2020',\n",
       "  'title': '4 bedroom character property',\n",
       "  'address': 'Hinton Road, London, SE24',\n",
       "  'miles from station': '0.56 miles from station',\n",
       "  'description': '** NO REFERENCING FEES ** Available at the end of February is this newly built townhouse located conveniently between Brixton and Herne Hill. Offering four good sized bedrooms, a family bathroom, an en suite to the master bedroom and a downstairs cloakroom as well as a private decked g...',\n",
       "  'price': '£3,200 pcm',\n",
       "  'date added/price changed': 'Added on 20/03/2020',\n",
       "  'agent': 'by Eaton Green Estate Agents, Camberwell',\n",
       "  'agent phone number': '020 8012 4142',\n",
       "  'link to property': 'https://www.rightmove.co.uk/property-to-rent/property-78333196.html'},\n",
       " {'date_added to file': '22/04/2020',\n",
       "  'title': '4 bedroom house',\n",
       "  'address': 'Solon Road, SW2',\n",
       "  'miles from station': '0.53 miles from station',\n",
       "  'description': 'A charming example of a four double bedroom Victorian house between Clapham and Brixton',\n",
       "  'price': '£3,510 pcm',\n",
       "  'date added/price changed': 'Added on 18/03/2020',\n",
       "  'agent': 'by Keating Estates, Clapham',\n",
       "  'agent phone number': '020 8012 2330',\n",
       "  'link to property': 'https://www.rightmove.co.uk/property-to-rent/property-90586844.html'},\n",
       " {'date_added to file': '22/04/2020',\n",
       "  'title': '4 bedroom terraced house',\n",
       "  'address': 'Brockwell Park Row, SW2',\n",
       "  'miles from station': '0.92 miles from station',\n",
       "  'description': 'A beautiful four bed, three bath town house overlooking tranquil Brockwell Park.',\n",
       "  'price': '£3,445 pcm',\n",
       "  'date added/price changed': 'Added on 13/03/2020',\n",
       "  'agent': 'by Keating Estates, Brixton',\n",
       "  'agent phone number': '020 8012 9055',\n",
       "  'link to property': 'https://www.rightmove.co.uk/property-to-rent/property-90434222.html'},\n",
       " {'date_added to file': '22/04/2020',\n",
       "  'title': '4 bedroom house',\n",
       "  'address': 'Plato Road, London',\n",
       "  'miles from station': '0.56 miles from station',\n",
       "  'description': 'A beautiful four double bedroom house close to both Clapham and Brixton.',\n",
       "  'price': '£3,380 pcm',\n",
       "  'date added/price changed': 'Added on 13/03/2020',\n",
       "  'agent': 'by Keating Estates, Clapham',\n",
       "  'agent phone number': '020 8012 2330',\n",
       "  'link to property': 'https://www.rightmove.co.uk/property-to-rent/property-90433730.html'},\n",
       " {'date_added to file': '22/04/2020',\n",
       "  'title': '4 bedroom terraced house',\n",
       "  'address': 'Abbeville Road, Clapham',\n",
       "  'miles from station': '0.97 miles from station',\n",
       "  'description': 'A four bedroom two bathroom Victorian terraced house split over three floors. Newly refurbished with a private garden, this property is suitable for professional sharers.',\n",
       "  'price': '£3,750 pcm',\n",
       "  'date added/price changed': 'Added on 10/03/2020',\n",
       "  'agent': 'by Jacksons Estate Agents, Clapham',\n",
       "  'agent phone number': '020 8012 0791',\n",
       "  'link to property': 'https://www.rightmove.co.uk/property-to-rent/property-90311705.html'},\n",
       " {'date_added to file': '22/04/2020',\n",
       "  'title': '4 bedroom mews house',\n",
       "  'address': 'Barnwell Road, SW2',\n",
       "  'miles from station': '0.39 miles from station',\n",
       "  'description': 'Large four double bedroom house with a private garden in Brixton',\n",
       "  'price': '£3,250 pcm',\n",
       "  'date added/price changed': 'Added on 10/03/2020',\n",
       "  'agent': 'by Keating Estates, Brixton',\n",
       "  'agent phone number': '020 8012 9055',\n",
       "  'link to property': 'https://www.rightmove.co.uk/property-to-rent/property-90291371.html'},\n",
       " {'date_added to file': '22/04/2020',\n",
       "  'title': '4 bedroom house',\n",
       "  'address': 'Mayall Road, Brixton, London, SE24',\n",
       "  'miles from station': '0.42 miles from station',\n",
       "  'description': 'Newly refurbished four double bedroom house located within walking distance of Brixton and Herne Hill. Double reception room, kitchen diner and two full sized bathrooms. Reclaimed pine flooring throughout the living spaces. Ideal for a family or 4 people sharing. ...',\n",
       "  'price': '£3,700 pcm',\n",
       "  'date added/price changed': 'Added on 09/03/2020',\n",
       "  'agent': 'by Petermans, West Dulwich',\n",
       "  'agent phone number': '020 3858 2761',\n",
       "  'link to property': 'https://www.rightmove.co.uk/property-to-rent/property-78074293.html'},\n",
       " {'date_added to file': '22/04/2020',\n",
       "  'title': '4 bedroom detached house',\n",
       "  'address': 'Branksome Road, Brixton',\n",
       "  'miles from station': '0.62 miles from station',\n",
       "  'description': 'VERY SPECIAL. - AVAILABLE WITH DEPOSIT FREE OPTION. This beautifully well presented large and spacious four double bedroom house with garden.',\n",
       "  'price': '£3,250 pcm',\n",
       "  'date added/price changed': 'Added on 02/03/2020',\n",
       "  'agent': 'by haart, Brixton - Lettings',\n",
       "  'agent phone number': '020 8012 1473',\n",
       "  'link to property': 'https://www.rightmove.co.uk/property-to-rent/property-90121943.html'}]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(results))\n",
    "print()\n",
    "results\n",
    "\n",
    "# produces dictionary within a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(results)\n",
    "df.to_csv('properties.csv',encoding='utf-8', mode='w')\n",
    "df.to_csv('properties_cumulative.csv',encoding='utf-8', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For more scraping see the Property_Scraper repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Using an API:\n",
    "\n",
    "The Rotten Tomatoes API in the tutorial has been taken down >:/\n",
    "\n",
    "So we'll play around with a free Twitter API.\n",
    "\n",
    "API Keys:\n",
    "* required for data access\n",
    "* identifies application (you)\n",
    "* monitors usage\n",
    "* limits rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-twitter in c:\\users\\chris\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: requests in c:\\users\\chris\\anaconda3\\lib\\site-packages (from python-twitter) (2.22.0)\n",
      "Requirement already satisfied: future in c:\\users\\chris\\anaconda3\\lib\\site-packages (from python-twitter) (0.18.2)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\chris\\anaconda3\\lib\\site-packages (from python-twitter) (1.3.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from requests->python-twitter) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from requests->python-twitter) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from requests->python-twitter) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from requests->python-twitter) (3.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from requests-oauthlib->python-twitter) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is extremely important to hide the API keys.\n",
    "\n",
    "We can use environmental variables for this: https://towardsdatascience.com/how-to-hide-your-api-keys-in-python-fb2e1a61b0a0\n",
    "\n",
    "(N.B. as an aside, this has introduced me to Virtual Environments! https://realpython.com/python-virtual-environments-a-primer/\n",
    "\n",
    "* conda install nb_conda in the terminal\n",
    "* conda create --name [name] --clone root in the terminal\n",
    "* and this article gives an explanation of how to add the environment to Jupyter https://medium.com/@nrk25693/how-to-add-your-conda-environment-to-your-jupyter-notebook-in-just-4-steps-abeab8b8d084)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "api = twitter.Api("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$CONDA_PREFIX\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Harvard]",
   "language": "python",
   "name": "conda-env-Harvard-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
